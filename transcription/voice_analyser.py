# ==============================================================================
# IMPORTS
# ==============================================================================
import io
import json
import base64
import asyncio
import tempfile
import os
import traceback
import time

# Imports for Web Server
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState

# Imports for Transcription
import whisper

# Imports for Voice Analysis
import numpy as np
import librosa

# ==============================================================================
# INITIALIZATION
# ==============================================================================

app = FastAPI()

# Load Whisper model
model_name = os.getenv("WHISPER_MODEL", "small").strip()
print(f"ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper '{model_name}'...")
model = whisper.load_model(model_name)
print(f"‚úÖ –ú–æ–¥–µ–ª—å Whisper '{model_name}' –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

# ==============================================================================
# VOICE ANALYSIS LOGIC (from voice_analyser.py)
# ==============================================================================

def extract_features(audio: np.ndarray, sr: int):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö."""
    features = {}
    print("üî¨ –ù–∞—á–∞–ª–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–∫—É—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    try:
        # –≠–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        energy = librosa.feature.rms(y=audio)[0]
        features['avg_energy'] = np.mean(energy)
        features['energy_std'] = np.std(energy)
        features['energy_stability'] = 1 / (np.std(energy) + 0.001)

        # –í—ã—Å–æ—Ç–∞ —Ç–æ–Ω–∞
        pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)
        pitch_values = pitches[pitches > 0]
        if len(pitch_values) > 0:
            features['avg_pitch'] = np.mean(pitch_values)
            features['pitch_std'] = np.std(pitch_values)
            features['pitch_stability'] = 1 / (np.std(pitch_values) + 0.1)
        else:
            features['avg_pitch'] = 0
            features['pitch_std'] = 0
            features['pitch_stability'] = 0

        # –¢–µ–º–ø –∏ —Ä–µ—á–µ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)
        features['tempo'] = tempo[0] if isinstance(tempo, np.ndarray) and tempo.size > 0 else tempo

        silence_threshold = np.mean(energy) * 0.15
        speech_frames = np.sum(energy > silence_threshold)
        features['speech_ratio'] = speech_frames / len(energy) if len(energy) > 0 else 0.0

        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
        features['spectral_brightness'] = np.mean(spectral_centroids)
        features['brightness_stability'] = 1 / (np.std(spectral_centroids) + 0.1)
        
        print("üëç –ü—Ä–∏–∑–Ω–∞–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã.")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        return {
            'avg_energy': 0.01, 'energy_std': 0.01, 'energy_stability': 1,
            'avg_pitch': 100, 'pitch_std': 10, 'pitch_stability': 1,
            'tempo': 120, 'speech_ratio': 0.5, 'spectral_brightness': 2000,
            'brightness_stability': 1,
            'error': str(e)
        }
    return features


def features_to_tags(features: dict):
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Ç–µ–≥–∏ —Å–æ—Ñ—Ç-—Å–∫–∏–ª–ª–æ–≤."""
    tags = []
    scores = {}
    print("üè∑Ô∏è –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —Ç–µ–≥–∏...")
    
    # –£–í–ï–†–ï–ù–ù–û–°–¢–¨
    confidence = 0
    if features.get('energy_stability', 0) > 10: confidence += 0.3
    if features.get('pitch_stability', 0) > 5: confidence += 0.3
    if 0.6 <= features.get('speech_ratio', 0) <= 0.85: confidence += 0.2
    if 80 <= features.get('tempo', 120) <= 140: confidence += 0.2
    if confidence >= 0.6: tags.append("–£–≤–µ—Ä–µ–Ω–Ω—ã–π")
    elif confidence >= 0.3: tags.append("–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–≤–µ—Ä–µ–Ω–Ω—ã–π")
    else: tags.append("–ù–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–π")
    scores['confidence'] = round(confidence * 100, 1)

    # –°–¢–†–ï–°–°–û–£–°–¢–û–ô–ß–ò–í–û–°–¢–¨
    stress_resistance = 0
    if features.get('pitch_std', 100) < 50: stress_resistance += 0.4
    if features.get('energy_std', 1) < 0.02: stress_resistance += 0.3
    if 90 <= features.get('tempo', 120) <= 130: stress_resistance += 0.3
    if stress_resistance >= 0.6: tags.append("–°—Ç—Ä–µ—Å—Å–æ—É—Å—Ç–æ–π—á–∏–≤—ã–π")
    elif stress_resistance >= 0.3: tags.append("–°—Ä–µ–¥–Ω—è—è —Å—Ç—Ä–µ—Å—Å–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å")
    else: tags.append("–ü–æ–¥–≤–µ—Ä–∂–µ–Ω —Å—Ç—Ä–µ—Å—Å—É")
    scores['stress_resistance'] = round(stress_resistance * 100, 1)

    # –ö–û–ú–ú–£–ù–ò–ö–ê–¢–ò–í–ù–û–°–¢–¨
    communication = 0
    if features.get('speech_ratio', 0) > 0.7: communication += 0.3
    if features.get('spectral_brightness', 0) > 2000: communication += 0.25
    if features.get('brightness_stability', 0) > 3: communication += 0.25
    if features.get('avg_energy', 0) > 0.03: communication += 0.2
    if communication >= 0.6: tags.append("–û—Ç–ª–∏—á–Ω–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è")
    elif communication >= 0.3: tags.append("–•–æ—Ä–æ—à–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è")
    else: tags.append("–°–ª–∞–±–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è")
    scores['communication'] = round(communication * 100, 1)

    # –≠–ù–ï–†–ì–ò–ß–ù–û–°–¢–¨
    energy_score = 0
    if features.get('avg_energy', 0) > 0.05: energy_score += 0.5
    if 110 <= features.get('tempo', 120) <= 160: energy_score += 0.5
    if energy_score >= 0.6: tags.append("–≠–Ω–µ—Ä–≥–∏—á–Ω—ã–π")
    elif energy_score >= 0.3: tags.append("–£–º–µ—Ä–µ–Ω–Ω–æ –∞–∫—Ç–∏–≤–Ω—ã–π")
    else: tags.append("–ü–∞—Å—Å–∏–≤–Ω—ã–π")
    scores['energy'] = round(energy_score * 100, 1)

    # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –¢–ï–ì–ò
    if features.get('tempo', 120) > 150: tags.append("–ë—ã—Å—Ç—Ä–∞—è —Ä–µ—á—å")
    elif features.get('tempo', 120) < 80: tags.append("–ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–µ—á—å")
    if features.get('avg_energy', 0) < 0.02: tags.append("–¢–∏—Ö–∏–π –≥–æ–ª–æ—Å")
    elif features.get('avg_energy', 0) > 0.1: tags.append("–ì—Ä–æ–º–∫–∏–π –≥–æ–ª–æ—Å")
    if features.get('pitch_std', 100) < 20: tags.append("–ú–æ–Ω–æ—Ç–æ–Ω–Ω—ã–π")
    
    # –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê
    overall_score = (scores['confidence'] * 0.3 + scores['communication'] * 0.3 + scores['stress_resistance'] * 0.25 + scores['energy'] * 0.15)
    
    print("üëç –¢–µ–≥–∏ –∏ –æ—Ü–µ–Ω–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã.")
    
    return {
        'tags': list(set(tags)), # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        'scores': scores,
        'overall_score': round(overall_score, 1)
    }

def analyze_audio_sync(audio_np: np.ndarray, sr: int):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—É–¥–∏–æ."""
    if audio_np.size == 0:
        print("‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—É—Å—Ç–æ–≥–æ –∞—É–¥–∏–æ –º–∞—Å—Å–∏–≤–∞.")
        return {
            'tags': ['–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'],
            'scores': {},
            'error': '–ù–µ—Ç –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'
        }
    
    start_time = time.time()
    features = extract_features(audio_np, sr)
    analysis_result = features_to_tags(features)
    processing_time = (time.time() - start_time) * 1000
    
    analysis_result['meta'] = {
        'total_duration': round(len(audio_np) / sr, 2),
        'processing_time_ms': round(processing_time, 1)
    }
    return analysis_result


def transcribe_audio_sync(audio_np: np.ndarray):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏."""
    if audio_np.size == 0:
        print("‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –ø—É—Å—Ç–æ–≥–æ –∞—É–¥–∏–æ –º–∞—Å—Å–∏–≤–∞.")
        return "–ü—É—Å—Ç–æ–π –∞—É–¥–∏–æ —Ñ–∞–π–ª"
        
    try:
        print(f"ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏...")
        start_time = time.time()
        result = model.transcribe(audio_np, language="ru")
        processing_time = time.time() - start_time
        print(f"üéØ Whisper –∑–∞–≤–µ—Ä—à–∏–ª –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞ {processing_time:.2f}—Å")
        
        transcribed_text = result["text"].strip()
        
        if not transcribed_text:
            print("‚ö†Ô∏è Whisper –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"
            
        return transcribed_text
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Whisper/FFmpeg: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤–æ–∑–Ω–∏–∫–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –æ—Ç–≤–µ—Ç –µ—â–µ —Ä–∞–∑."

# ==============================================================================
# WEBSOCKET LOGIC
# ==============================================================================

@app.websocket("/ws/voice")
async def websocket_voice(websocket: WebSocket):
    print("üîó –ù–æ–≤–æ–µ WebSocket –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")
    await websocket.accept()
    print("‚úÖ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ")
    
    audio_buffer = io.BytesIO()
    chunks_received = 0
    
    try:
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            if message['type'] == 'audio_chunk':
                chunk_b64 = message['data']
                chunk_bytes = base64.b64decode(chunk_b64)
                audio_buffer.write(chunk_bytes)
                chunks_received += 1
                
                if chunks_received % 20 == 0:
                    print(f"üéµ –ü–æ–ª—É—á–µ–Ω–æ {chunks_received} —á–∞–Ω–∫–æ–≤, –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {audio_buffer.tell()} –±–∞–π—Ç")

            elif message['type'] == 'end':
                print("üèÅ –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏.")
                print(f"üìà –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {chunks_received}")
                
                audio_bytes = audio_buffer.getvalue()
                
                if len(audio_bytes) == 0:
                    print("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–æ –ø—É—Å—Ç–æ–µ –∞—É–¥–∏–æ. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –∫–ª–∏–µ–Ω—Ç—É.")
                    if websocket.application_state == WebSocketState.CONNECTED:
                        await websocket.send_json({'type': 'error', 'message': '–ê—É–¥–∏–æ–∑–∞–ø–∏—Å—å –ø—É—Å—Ç–∞.'})
                    continue # –ñ–¥–µ–º —Å–ª–µ–¥—É—é—â—É—é –∑–∞–ø–∏—Å—å

                print(f"üéß –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∞—É–¥–∏–æ —Ä–∞–∑–º–µ—Ä–æ–º {len(audio_bytes)} –±–∞–π—Ç")
                loop = asyncio.get_event_loop()
                
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
                temp_audio_file = tempfile.NamedTemporaryFile(suffix=".webm", delete=False)
                temp_file_path = temp_audio_file.name
                
                try:
                    temp_audio_file.write(audio_bytes)
                    temp_audio_file.close()
                    print(f"üíæ –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∞–Ω—ã –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {temp_file_path}")

                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ numpy array —Å –ø–æ–º–æ—â—å—é librosa
                    # –≠—Ç–æ CPU-bound –æ–ø–µ—Ä–∞—Ü–∏—è, –Ω–æ librosa.load –±—ã—Å—Ç—Ä–∞—è –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    print("üîÑ –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ –≤ numpy array...")
                    start_decode = time.time()
                    audio_np, sr = librosa.load(temp_file_path, sr=16000, mono=True)
                    print(f"‚úÖ –ê—É–¥–∏–æ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–æ –∑–∞ {time.time() - start_decode:.2f}—Å. –°—ç–º–ø–ª–æ–≤: {len(audio_np)}, –ß–∞—Å—Ç–æ—Ç–∞: {sr}Hz")

                    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö
                    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∏ –∞–Ω–∞–ª–∏–∑ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...")
                    transcribe_task = loop.run_in_executor(None, transcribe_audio_sync, audio_np)
                    analyze_task = loop.run_in_executor(None, analyze_audio_sync, audio_np, sr)
                    
                    # –û–∂–∏–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    transcription_result = await transcribe_task
                    analysis_result = await analyze_task
                    
                    print(f"üìù –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: '{transcription_result}'")
                    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞: {analysis_result['tags']}")
                    
                    if websocket.application_state == WebSocketState.CONNECTED:
                        response = {
                            'type': 'final_result',
                            'transcription': transcription_result,
                            'analysis': analysis_result
                        }
                        print(f"üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∏–µ–Ω—Ç—É...")
                        await websocket.send_json(response)
                        print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω")
                    else:
                        print("‚ùå WebSocket –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω, –Ω–µ –º–æ–∂–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç")

                finally:
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    if os.path.exists(temp_file_path):
                        os.unlink(temp_file_path)
                        print(f"üóëÔ∏è –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω: {temp_file_path}")

                # –°–±—Ä–æ—Å –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–ø–∏—Å–∏
                audio_buffer = io.BytesIO()
                chunks_received = 0
                print("\nüîÑ –ë—É—Ñ–µ—Ä —Å–±—Ä–æ—à–µ–Ω, –≥–æ—Ç–æ–≤ –∫ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å–∏.")

    except WebSocketDisconnect:
        print("üîå –ö–ª–∏–µ–Ω—Ç –æ—Ç–∫–ª—é—á–∏–ª—Å—è –æ—Ç WebSocket.")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ WebSocket: {e}")
        traceback.print_exc()
    finally:
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –±—É—Ñ–µ—Ä –∑–∞–∫—Ä—ã—Ç
        if not audio_buffer.closed:
            audio_buffer.close()


# ==============================================================================
# MAIN EXECUTION
# ==============================================================================

if __name__ == "__main__":
    import uvicorn
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ Uvicorn –Ω–∞ http://0.0.0.0:8001")
    uvicorn.run(app, host="0.0.0.0", port=8001, reload=False)
